{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d8d24be-39c7-4ee4-9774-29c102187500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf19b041-e783-4680-9af6-a2c54a9c34e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 및 전처리\n",
    "df = pd.read_csv('C:/dataset/abalone.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0761cc9-54b9-4934-8acd-a7089720cce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>4172</td>\n",
       "      <td>F</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>4173</td>\n",
       "      <td>M</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>4174</td>\n",
       "      <td>M</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>4175</td>\n",
       "      <td>F</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>4176</td>\n",
       "      <td>M</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
       "0        0   M   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1        1   M   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2        2   F   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3        3   M   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4        4   I   0.330     0.255   0.080        0.2050          0.0895   \n",
       "...    ...  ..     ...       ...     ...           ...             ...   \n",
       "4172  4172   F   0.565     0.450   0.165        0.8870          0.3700   \n",
       "4173  4173   M   0.590     0.440   0.135        0.9660          0.4390   \n",
       "4174  4174   M   0.600     0.475   0.205        1.1760          0.5255   \n",
       "4175  4175   F   0.625     0.485   0.150        1.0945          0.5310   \n",
       "4176  4176   M   0.710     0.555   0.195        1.9485          0.9455   \n",
       "\n",
       "      Viscera_weight  Shell_weight  Rings  \n",
       "0             0.1010        0.1500     15  \n",
       "1             0.0485        0.0700      7  \n",
       "2             0.1415        0.2100      9  \n",
       "3             0.1140        0.1550     10  \n",
       "4             0.0395        0.0550      7  \n",
       "...              ...           ...    ...  \n",
       "4172          0.2390        0.2490     11  \n",
       "4173          0.2145        0.2605     10  \n",
       "4174          0.2875        0.3080      9  \n",
       "4175          0.2610        0.2960     10  \n",
       "4176          0.3765        0.4950     12  \n",
       "\n",
       "[4177 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d113563-f538-4d51-9a4e-d17fbc4c5e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류를 위한 Rings 카테고리화\n",
    "def categorize_rings(rings):\n",
    "    if rings <= 8:\n",
    "        return 0    # 어린 전복\n",
    "    elif rings <= 12:\n",
    "        return 1    # 중간 전복\n",
    "    else:\n",
    "        return 2    # 성숙 전복\n",
    "\n",
    "df['Rings_category'] = df['Rings'].apply(categorize_rings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "301df6e7-7adc-4b13-b6e6-db30eb7dc36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sex 원-핫 인코딩\n",
    "df = pd.get_dummies(df, columns=['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eda1dee-edba-4e4c-8236-90af4ae390cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성과 타겟 분리\n",
    "X = df.drop(['Rings', 'Rings_category', 'id'], axis=1)\n",
    "y = df['Rings_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f96f51ee-7c1b-40cd-9e4c-e96137a85d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adbf0680-1709-40a8-aad7-a2e3584374bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 입력을 위한 reshape\n",
    "X_reshaped = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fea5ac73-035b-4c11-a7d0-0df8a74c254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원-핫 인코딩\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "346858b1-f943-41bc-a5bd-a7af2d8f769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62a601f9-b04e-4dda-9809-e32e6663a8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\김경환\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# CNN 분류 모델\n",
    "model_clf = Sequential([\n",
    "    Conv1D(64, 2, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(2),\n",
    "    \n",
    "    Conv1D(128, 2, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(2),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89742ad9-032a-465d-a7d9-1851f05f45ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clf.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97fcdf59-38f3-4580-8826-194d7964bf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\김경환\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.6159 - loss: 0.9313 - val_accuracy: 0.6233 - val_loss: 0.9918\n",
      "Epoch 2/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6563 - loss: 0.7801 - val_accuracy: 0.6756 - val_loss: 0.9034\n",
      "Epoch 3/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6769 - loss: 0.7483 - val_accuracy: 0.6697 - val_loss: 0.8378\n",
      "Epoch 4/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6823 - loss: 0.7406 - val_accuracy: 0.6622 - val_loss: 0.7796\n",
      "Epoch 5/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7007 - loss: 0.7180 - val_accuracy: 0.6667 - val_loss: 0.7505\n",
      "Epoch 6/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6900 - loss: 0.7263 - val_accuracy: 0.6517 - val_loss: 0.7604\n",
      "Epoch 7/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6882 - loss: 0.7083 - val_accuracy: 0.6906 - val_loss: 0.7073\n",
      "Epoch 8/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6863 - loss: 0.7088 - val_accuracy: 0.6981 - val_loss: 0.6956\n",
      "Epoch 9/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6998 - loss: 0.6922 - val_accuracy: 0.6667 - val_loss: 0.7256\n",
      "Epoch 10/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6881 - loss: 0.7121 - val_accuracy: 0.7055 - val_loss: 0.6789\n",
      "Epoch 11/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7129 - loss: 0.6695 - val_accuracy: 0.6936 - val_loss: 0.6802\n",
      "Epoch 12/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7126 - loss: 0.6758 - val_accuracy: 0.6906 - val_loss: 0.6815\n",
      "Epoch 13/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7308 - loss: 0.6581 - val_accuracy: 0.6906 - val_loss: 0.6811\n",
      "Epoch 14/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7219 - loss: 0.6796 - val_accuracy: 0.7085 - val_loss: 0.6775\n",
      "Epoch 15/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7258 - loss: 0.6596 - val_accuracy: 0.7145 - val_loss: 0.6712\n",
      "Epoch 16/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7288 - loss: 0.6442 - val_accuracy: 0.7100 - val_loss: 0.6719\n",
      "Epoch 17/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7074 - loss: 0.6811 - val_accuracy: 0.6876 - val_loss: 0.6690\n",
      "Epoch 18/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7258 - loss: 0.6519 - val_accuracy: 0.6966 - val_loss: 0.6692\n",
      "Epoch 19/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7133 - loss: 0.6522 - val_accuracy: 0.6876 - val_loss: 0.6876\n",
      "Epoch 20/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7150 - loss: 0.6690 - val_accuracy: 0.7160 - val_loss: 0.6686\n",
      "Epoch 21/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7071 - loss: 0.6626 - val_accuracy: 0.6996 - val_loss: 0.6833\n",
      "Epoch 22/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7192 - loss: 0.6364 - val_accuracy: 0.7070 - val_loss: 0.6742\n",
      "Epoch 23/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7389 - loss: 0.6324 - val_accuracy: 0.6951 - val_loss: 0.6642\n",
      "Epoch 24/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7170 - loss: 0.6573 - val_accuracy: 0.7115 - val_loss: 0.6621\n",
      "Epoch 25/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7176 - loss: 0.6526 - val_accuracy: 0.7010 - val_loss: 0.6692\n",
      "Epoch 26/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7305 - loss: 0.6379 - val_accuracy: 0.7190 - val_loss: 0.6673\n",
      "Epoch 27/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7246 - loss: 0.6541 - val_accuracy: 0.7040 - val_loss: 0.6739\n",
      "Epoch 28/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7337 - loss: 0.6453 - val_accuracy: 0.6966 - val_loss: 0.6628\n",
      "Epoch 29/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7246 - loss: 0.6200 - val_accuracy: 0.7040 - val_loss: 0.6651\n",
      "Epoch 30/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7194 - loss: 0.6446 - val_accuracy: 0.6966 - val_loss: 0.6806\n",
      "Epoch 31/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7442 - loss: 0.6320 - val_accuracy: 0.7145 - val_loss: 0.6761\n",
      "Epoch 32/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7273 - loss: 0.6435 - val_accuracy: 0.7085 - val_loss: 0.6729\n",
      "Epoch 33/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7028 - loss: 0.6530 - val_accuracy: 0.7055 - val_loss: 0.6724\n",
      "Epoch 34/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7306 - loss: 0.6385 - val_accuracy: 0.6996 - val_loss: 0.6642\n",
      "Epoch 35/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7284 - loss: 0.6245 - val_accuracy: 0.7070 - val_loss: 0.6865\n",
      "Epoch 36/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.7344 - loss: 0.6223 - val_accuracy: 0.7025 - val_loss: 0.6712\n",
      "Epoch 37/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7370 - loss: 0.6135 - val_accuracy: 0.6951 - val_loss: 0.6641\n",
      "Epoch 38/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7397 - loss: 0.6227 - val_accuracy: 0.7040 - val_loss: 0.6816\n",
      "Epoch 39/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7419 - loss: 0.5941 - val_accuracy: 0.6816 - val_loss: 0.6848\n",
      "Epoch 40/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7236 - loss: 0.6323 - val_accuracy: 0.7025 - val_loss: 0.6761\n",
      "Epoch 41/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7404 - loss: 0.6305 - val_accuracy: 0.7025 - val_loss: 0.6988\n",
      "Epoch 42/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7356 - loss: 0.6221 - val_accuracy: 0.7100 - val_loss: 0.6776\n",
      "Epoch 43/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7360 - loss: 0.6153 - val_accuracy: 0.6861 - val_loss: 0.6673\n",
      "Epoch 44/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7566 - loss: 0.5941 - val_accuracy: 0.6921 - val_loss: 0.6672\n",
      "Epoch 45/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7377 - loss: 0.6135 - val_accuracy: 0.7040 - val_loss: 0.6730\n",
      "Epoch 46/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7380 - loss: 0.6051 - val_accuracy: 0.6981 - val_loss: 0.6777\n",
      "Epoch 47/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7511 - loss: 0.6080 - val_accuracy: 0.6786 - val_loss: 0.6838\n",
      "Epoch 48/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7443 - loss: 0.5981 - val_accuracy: 0.6921 - val_loss: 0.6995\n",
      "Epoch 49/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7388 - loss: 0.5809 - val_accuracy: 0.7025 - val_loss: 0.6764\n",
      "Epoch 50/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7422 - loss: 0.6104 - val_accuracy: 0.7055 - val_loss: 0.6744\n",
      "Epoch 51/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7353 - loss: 0.6014 - val_accuracy: 0.7025 - val_loss: 0.6816\n",
      "Epoch 52/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7506 - loss: 0.5817 - val_accuracy: 0.6861 - val_loss: 0.6837\n",
      "Epoch 53/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7423 - loss: 0.6076 - val_accuracy: 0.7085 - val_loss: 0.6797\n",
      "Epoch 54/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7641 - loss: 0.5703 - val_accuracy: 0.7190 - val_loss: 0.6694\n",
      "Epoch 55/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7395 - loss: 0.6044 - val_accuracy: 0.6891 - val_loss: 0.6950\n",
      "Epoch 56/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7526 - loss: 0.5799 - val_accuracy: 0.7085 - val_loss: 0.6675\n",
      "Epoch 57/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7378 - loss: 0.5926 - val_accuracy: 0.6936 - val_loss: 0.6956\n",
      "Epoch 58/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7532 - loss: 0.5707 - val_accuracy: 0.7055 - val_loss: 0.6676\n",
      "Epoch 59/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7490 - loss: 0.5772 - val_accuracy: 0.7130 - val_loss: 0.6575\n",
      "Epoch 60/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7594 - loss: 0.5585 - val_accuracy: 0.6996 - val_loss: 0.6873\n",
      "Epoch 61/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7443 - loss: 0.5752 - val_accuracy: 0.6921 - val_loss: 0.6790\n",
      "Epoch 62/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7357 - loss: 0.5879 - val_accuracy: 0.6801 - val_loss: 0.6989\n",
      "Epoch 63/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7362 - loss: 0.5848 - val_accuracy: 0.6906 - val_loss: 0.6847\n",
      "Epoch 64/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7559 - loss: 0.5856 - val_accuracy: 0.6981 - val_loss: 0.6809\n",
      "Epoch 65/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7473 - loss: 0.5819 - val_accuracy: 0.6712 - val_loss: 0.7272\n",
      "Epoch 66/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7469 - loss: 0.5911 - val_accuracy: 0.7100 - val_loss: 0.6869\n",
      "Epoch 67/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7495 - loss: 0.5890 - val_accuracy: 0.7085 - val_loss: 0.6801\n",
      "Epoch 68/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7284 - loss: 0.5927 - val_accuracy: 0.6996 - val_loss: 0.6807\n",
      "Epoch 69/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7471 - loss: 0.5688 - val_accuracy: 0.6876 - val_loss: 0.6968\n",
      "Epoch 70/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7669 - loss: 0.5589 - val_accuracy: 0.7070 - val_loss: 0.6842\n",
      "Epoch 71/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7502 - loss: 0.5758 - val_accuracy: 0.6996 - val_loss: 0.7003\n",
      "Epoch 72/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7472 - loss: 0.5887 - val_accuracy: 0.6951 - val_loss: 0.6908\n",
      "Epoch 73/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7437 - loss: 0.5887 - val_accuracy: 0.7055 - val_loss: 0.6959\n",
      "Epoch 74/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7389 - loss: 0.5744 - val_accuracy: 0.6936 - val_loss: 0.6801\n",
      "Epoch 75/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7512 - loss: 0.5718 - val_accuracy: 0.7055 - val_loss: 0.6844\n",
      "Epoch 76/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7448 - loss: 0.5761 - val_accuracy: 0.6906 - val_loss: 0.7088\n",
      "Epoch 77/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7404 - loss: 0.5746 - val_accuracy: 0.6996 - val_loss: 0.6878\n",
      "Epoch 78/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7520 - loss: 0.5808 - val_accuracy: 0.7100 - val_loss: 0.6965\n",
      "Epoch 79/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7519 - loss: 0.5646 - val_accuracy: 0.7294 - val_loss: 0.6857\n",
      "Epoch 80/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7570 - loss: 0.5545 - val_accuracy: 0.7100 - val_loss: 0.6983\n",
      "Epoch 81/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7541 - loss: 0.5572 - val_accuracy: 0.6816 - val_loss: 0.7181\n",
      "Epoch 82/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7507 - loss: 0.5620 - val_accuracy: 0.7055 - val_loss: 0.6944\n",
      "Epoch 83/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7477 - loss: 0.5745 - val_accuracy: 0.7010 - val_loss: 0.6891\n",
      "Epoch 84/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7669 - loss: 0.5507 - val_accuracy: 0.6816 - val_loss: 0.6931\n",
      "Epoch 85/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7626 - loss: 0.5515 - val_accuracy: 0.7085 - val_loss: 0.6964\n",
      "Epoch 86/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7621 - loss: 0.5562 - val_accuracy: 0.7190 - val_loss: 0.7070\n",
      "Epoch 87/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7529 - loss: 0.5585 - val_accuracy: 0.6981 - val_loss: 0.7089\n",
      "Epoch 88/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7616 - loss: 0.5614 - val_accuracy: 0.6876 - val_loss: 0.6970\n",
      "Epoch 89/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7603 - loss: 0.5362 - val_accuracy: 0.6996 - val_loss: 0.7363\n",
      "Epoch 90/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7576 - loss: 0.5577 - val_accuracy: 0.6996 - val_loss: 0.7037\n",
      "Epoch 91/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7687 - loss: 0.5502 - val_accuracy: 0.6906 - val_loss: 0.7183\n",
      "Epoch 92/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7545 - loss: 0.5550 - val_accuracy: 0.7025 - val_loss: 0.7215\n",
      "Epoch 93/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7615 - loss: 0.5462 - val_accuracy: 0.6966 - val_loss: 0.7054\n",
      "Epoch 94/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7667 - loss: 0.5562 - val_accuracy: 0.6966 - val_loss: 0.7181\n",
      "Epoch 95/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7756 - loss: 0.5234 - val_accuracy: 0.7055 - val_loss: 0.6942\n",
      "Epoch 96/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7708 - loss: 0.5351 - val_accuracy: 0.7130 - val_loss: 0.7147\n",
      "Epoch 97/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7650 - loss: 0.5420 - val_accuracy: 0.7070 - val_loss: 0.7037\n",
      "Epoch 98/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7810 - loss: 0.5366 - val_accuracy: 0.7055 - val_loss: 0.6967\n",
      "Epoch 99/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7776 - loss: 0.5149 - val_accuracy: 0.7085 - val_loss: 0.7088\n",
      "Epoch 100/100\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7700 - loss: 0.5532 - val_accuracy: 0.7070 - val_loss: 0.7165\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "history_clf = model_clf.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399cd24-ba6e-45f6-824f-462613ac70f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
